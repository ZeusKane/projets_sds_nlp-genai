{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Chargement des données\n",
    "\n",
    "Charger le fichier meta.jsonl en Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de descriptions chargées : 1000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Chargement des données\n",
    "file_path = \"meta.jsonl\"\n",
    "data = []\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "print(f\"Nombre de descriptions chargées : {len(data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Prétraitement et segmentation des textes\n",
    "Diviser les descriptions en morceaux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution  : \n",
    "Transformation préalable des descriptions qui sont des listes en chaînes de caractères avant de les traiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de produits traités : 1000\n",
      "Nombre total de morceaux générés : 969\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Initialisation du Text Splitter\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=128)\n",
    "product_chunks = []  # Liste pour stocker les morceaux par produit\n",
    "\n",
    "# Transformation préalable des descriptions en chaînes si elles sont des listes\n",
    "for item in data:\n",
    "    if 'description' in item:\n",
    "        description = item['description']\n",
    "        if isinstance(description, list):\n",
    "            # Si c'est une liste, on la convertit en chaîne de caractères\n",
    "            description = \" \".join(description)\n",
    "        \n",
    "        # On divise la description convertie en texte\n",
    "        chunks_for_product = splitter.split_text(description)\n",
    "        \n",
    "        # Ajouter les morceaux du produit actuel dans la liste\n",
    "        product_chunks.append(chunks_for_product)\n",
    "\n",
    "print(f\"Nombre de produits traités : {len(product_chunks)}\")\n",
    "print(f\"Nombre total de morceaux générés : {sum(len(chunks) for chunks in product_chunks)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Création d'un index vectoriel\n",
    "Générer des embeddings à l’aide de OllamaEmbeddings.\n",
    "Création de la base de données chrome.\n",
    "5. Création d’un système de récupération\n",
    "6. Conception d'une chaîne RAG\n",
    "7. Exécution de requetes utilisateurs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réponse générée : Le mieux adapté pour votre smartphone Samsung Galaxy Note 5 est une étui de protection, car il vous permettra d'assurer la sécurité et l'entretien régulier de votre appareil. Les accessoires à clip ou à attaches sont souvent utiles dans ce contexte pour repositionner ou retenir le téléphone sur divers supports tout en conservant les fonctionnalités et performances du smartphone original.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.schema import Document\n",
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Charger une partie des données depuis le fichier cleaned_product_descriptions.jsonl\n",
    "with open('cleaned_product_descriptions.jsonl', 'r') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "# Limiter les données à 1/50\n",
    "data = data[:len(data) // 50]\n",
    "\n",
    "# Extraire les descriptions\n",
    "descriptions = [item['description'] for item in data if 'description' in item and item['description']]\n",
    "\n",
    "# Découper les descriptions en morceaux\n",
    "chunk_size = 256\n",
    "chunk_overlap = 64\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "chunks = [splitter.split_text(description) for description in descriptions]\n",
    "\n",
    "# Aplatir les chunks\n",
    "flat_chunks = [chunk for sublist in chunks for chunk in sublist]\n",
    "\n",
    "# Encapsuler les chunks dans des objets Document\n",
    "documents = [Document(page_content=chunk) for chunk in flat_chunks]\n",
    "\n",
    "# Utiliser Ollama pour les embeddings\n",
    "embedding_model = OllamaEmbeddings(model=\"stablelm2\")\n",
    "\n",
    "# Diviser les chunks en lots\n",
    "batch_size = 50\n",
    "batches = [documents[i:i + batch_size] for i in range(0, len(documents), batch_size)]\n",
    "\n",
    "# Créer les embeddings\n",
    "embeddings = []\n",
    "for batch in batches:\n",
    "    batch_embeddings = embedding_model.embed_documents([doc.page_content for doc in batch])  # Utiliser page_content\n",
    "    embeddings.extend(batch_embeddings)\n",
    "\n",
    "# Création de la base de données vectorielle avec Chroma\n",
    "vectorstore = Chroma.from_documents(documents, embedding_model)\n",
    "\n",
    "# Configuration du retriever\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Utiliser Ollama pour le LLM\n",
    "llm = Ollama(model=\"stablelm2\")\n",
    "\n",
    "# Définir le système de prompt\n",
    "system_prompt = (\n",
    "    \"Use the given context to answer the question. \"\n",
    "    \"If you don't know the answer, say you don't know. \"\n",
    "    \"Use three sentence maximum and keep the answer concise. \"\n",
    "    \"Context: {context}\"\n",
    ")\n",
    "\n",
    "# Créer le prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Créer la chaîne de récupération avec le prompt\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "# Exemple de requête\n",
    "query = \"Quel est le meilleur produit pour Samsung Galaxy Note 5 ?\"\n",
    "\n",
    "# Exécuter la chaîne de récupération\n",
    "response = chain.invoke({\"input\": query})\n",
    "\n",
    "# Afficher seulement la réponse générée\n",
    "print(f\"Réponse générée : {response['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réponse générée : {'input': 'Quel est le meilleur produit pour Samsung Galaxy Note 5 ?', 'context': [Document(metadata={}, page_content='the base; you can reposition and Reattach time and time again. Youll always have the exact grip or Stand you need.'), Document(metadata={}, page_content='the base; you can reposition and Reattach time and time again. Youll always have the exact grip or Stand you need.'), Document(metadata={}, page_content='the base; you can reposition and Reattach time and time again. Youll always have the exact grip or Stand you need.'), Document(metadata={}, page_content='the base; you can reposition and Reattach time and time again. Youll always have the exact grip or Stand you need.')], 'answer': \"Afin de choisir le meilleur produit pour votre smartphone Samsung Galaxy Note 5, il convient d'évaluer plusieurs facteurs, tels que la RAM, le stockage et les performances générales. Les options suivantes offrent des configurations optimales pour ce modèle de smartphone :\\n\\n\\n1. Google Pixel 4a (6 Go + 16 Go) avec Android 11 - 4 Go RAM et 64 Go stock\\n2 L'iPhone SE (6 Go + 1 GB RAM) avec iOS 14 à jour et des performances rapides pour les applications récentes\\n3 Samsung Galaxy S21 (12 Go + 25 Go RAM) avec Android 11, 12 Go RAM, et un grand stockage de 512 Go\\n\\n\\nCes configurations répondent aux besoins courants pour la majorité des utilisateurs. Toutefois, il est important de considérer vos besoins spécifiques avant de choisir le meilleur produit pour votre Samsung Galaxy Note 5.\"}\n"
     ]
    }
   ],
   "source": [
    "# la chaîne de récupération\n",
    "response = chain.invoke({\"input\": query})\n",
    "\n",
    "# Afficher la réponse complète pour vérifier sa structure\n",
    "print(f\"Réponse générée : {response}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définition de RAG :\n",
    "\n",
    "Une chaîne RAG combine une recherche d'information (retrieval) dans une base de données ou un ensemble de documents \n",
    "avec un modèle génératif (LLM) pour produire des réponses précises et contextuelles.\n",
    "\n",
    "Fonctionnement dans ce code :\n",
    "\n",
    "Étape 1 : Préparation des données : Les documents sont découpés en morceaux (chunks) et convertis en une base de données vectorielles (Chroma).\n",
    "Étape 2 : Récupération (retrieval) : Le modèle trouve les documents pertinents pour répondre à une requête utilisateur.\n",
    "Étape 3 : Génération (Generation) : Les documents récupérés sont utilisés comme contexte pour un modèle de langage (LLM, ici Ollama) \n",
    "afin de générer une réponse concise et contextualisée."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
